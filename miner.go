package main

import (
	"bufio"
	"bytes"
	"context"
	"encoding/hex"
	"encoding/json"
	"errors"
	"io"
	"math"
	"math/big"
	"math/bits"
	"net"
	"strconv"
	"strings"
	"sync"
	"sync/atomic"
	"time"
)

// Helper functions for atomic float64 operations (stored as uint64 bits)
func atomicLoadFloat64(addr *atomic.Uint64) float64 {
	return math.Float64frombits(addr.Load())
}

func atomicStoreFloat64(addr *atomic.Uint64, val float64) {
	addr.Store(math.Float64bits(val))
}

type StratumRequest struct {
	ID     interface{}   `json:"id"`
	Method string        `json:"method"`
	Params []interface{} `json:"params"`
}

type StratumResponse struct {
	ID     interface{} `json:"id"`
	Result interface{} `json:"result"`
	Error  interface{} `json:"error"`
}

func newStratumError(code int, msg string) []interface{} {
	return []interface{}{code, msg, nil}
}

type VarDiffConfig struct {
	MinDiff            float64
	MaxDiff            float64
	TargetSharesPerMin float64
	AdjustmentWindow   time.Duration
	Step               float64
	MaxBurstShares     int
	BurstWindow        time.Duration
	// DampingFactor controls how aggressively vardiff moves toward target.
	// 1.0 = full correction (old behavior), 0.5 = move halfway, etc.
	// Lower values reduce overshoot. Typical range: 0.5-0.85.
	DampingFactor float64
}

type MinerStats struct {
	Worker            string
	WorkerSHA256      string
	Accepted          int64
	Rejected          int64
	TotalDifficulty   float64
	WindowDifficulty  float64
	LastShare         time.Time
	WindowStart       time.Time
	WindowAccepted    int
	WindowSubmissions int
}

// statsUpdate represents a stats modification to be processed asynchronously
type statsUpdate struct {
	worker       string
	accepted     bool
	creditedDiff float64
	shareDiff    float64
	reason       string
	shareHash    string
	detail       *ShareDetail
	timestamp    time.Time
}

type workerWalletState struct {
	address   string
	script    []byte
	validated bool
}

var defaultVarDiff = VarDiffConfig{
	MinDiff:            defaultMinDifficulty,
	MaxDiff:            defaultMaxDifficulty,
	TargetSharesPerMin: defaultVarDiffTargetSharesPerMin, // aim for roughly one share every 12s
	AdjustmentWindow:   defaultVarDiffAdjustmentWindow,
	Step:               defaultVarDiffStep,
	MaxBurstShares:     defaultVarDiffMaxBurstShares, // throttle spammy submitters
	BurstWindow:        defaultVarDiffBurstWindow,
	DampingFactor:      defaultVarDiffDampingFactor, // move 50% toward target to reduce overshoot
}

var nextConnectionID uint64

// duplicateShareKey is a compact, comparable representation of a share
// submission used for duplicate detection. It stores a bounded prefix of
// the concatenated extranonce2, ntime, nonce, and version fields.
type duplicateShareKey struct {
	n   uint8
	buf [maxDuplicateShareKeyBytes]byte
}

// duplicateShareSet is a hash-based duplicate detection cache with bounded size.
// Uses LRU eviction to remove oldest entries when at capacity.
type duplicateShareSet struct {
	m     map[duplicateShareKey]struct{}
	order []duplicateShareKey // Track insertion order for LRU eviction
}

// evictedCacheEntry holds a share cache for an evicted job during grace period.
type evictedCacheEntry struct {
	cache     *duplicateShareSet
	evictedAt time.Time
}

func makeDuplicateShareKey(dst *duplicateShareKey, extranonce2, ntime, nonce string, version uint32) {
	*dst = duplicateShareKey{}
	write := func(s string) {
		for i := 0; i < len(s) && int(dst.n) < maxDuplicateShareKeyBytes; i++ {
			dst.buf[dst.n] = s[i]
			dst.n++
		}
	}
	writeUint32Hex := func(v uint32) {
		const hexChars = "0123456789abcdef"
		for shift := 28; shift >= 0 && int(dst.n) < maxDuplicateShareKeyBytes; shift -= 4 {
			dst.buf[dst.n] = hexChars[int((v>>uint(shift))&0xF)]
			dst.n++
		}
	}
	if dst.n < maxDuplicateShareKeyBytes {
		write(extranonce2)
	}
	if dst.n < maxDuplicateShareKeyBytes {
		dst.buf[dst.n] = ':'
		dst.n++
	}
	if dst.n < maxDuplicateShareKeyBytes {
		write(ntime)
	}
	if dst.n < maxDuplicateShareKeyBytes {
		dst.buf[dst.n] = ':'
		dst.n++
	}
	if dst.n < maxDuplicateShareKeyBytes {
		write(nonce)
	}
	if dst.n < maxDuplicateShareKeyBytes {
		dst.buf[dst.n] = ':'
		dst.n++
	}
	if dst.n < maxDuplicateShareKeyBytes {
		writeUint32Hex(version)
	}
}

// seenOrAdd reports whether key has already been seen, and records it if not.
// O(1) lookup via hash map. Uses LRU eviction when reaching capacity.
func (s *duplicateShareSet) seenOrAdd(key duplicateShareKey) bool {
	if s.m == nil {
		s.m = make(map[duplicateShareKey]struct{}, duplicateShareHistory)
		s.order = make([]duplicateShareKey, 0, duplicateShareHistory)
	}

	if _, seen := s.m[key]; seen {
		return true
	}

	// Evict oldest 10% when at capacity (keeps 90% of recent history)
	if len(s.order) >= duplicateShareHistory {
		evictCount := duplicateShareHistory / 10
		if evictCount < 1 {
			evictCount = 1
		}
		for i := 0; i < evictCount; i++ {
			delete(s.m, s.order[i])
		}
		s.order = s.order[evictCount:]
	}

	// Add new key
	s.m[key] = struct{}{}
	s.order = append(s.order, key)

	return false
}

type MinerConn struct {
	id                   string
	ctx                  context.Context
	conn                 net.Conn
	writer               *bufio.Writer
	writeMu              sync.Mutex
	reader               *bufio.Reader
	jobMgr               *JobManager
	rpc                  rpcCaller
	cfg                  Config
	extranonce1          []byte
	jobCh                chan *Job
	difficulty           atomic.Uint64 // float64 stored as bits
	previousDifficulty   atomic.Uint64 // float64 stored as bits
	shareTarget          atomic.Pointer[big.Int]
	lastDiffChange       atomic.Int64 // Unix nanos
	stateMu              sync.Mutex
	listenerOn           bool
	stats                MinerStats
	statsMu              sync.Mutex
	initWorkMu           sync.Mutex
	statsUpdates         chan statsUpdate // Buffered channel for async stats updates
	statsWg              sync.WaitGroup   // Wait for stats worker to finish
	vardiff              VarDiffConfig
	metrics              *PoolMetrics
	accounting           *AccountStore
	workerRegistry       *workerConnectionRegistry
	savedWorkerStore     *workerListStore
	discordNotifier      *discordNotifier
	savedWorkerTracked   bool
	savedWorkerBestDiff  float64
	registeredWorker     string
	registeredWorkerHash string
	jobMu                sync.Mutex
	activeJobs           map[string]*Job
	jobOrder             []string
	maxRecentJobs        int
	shareCache           map[string]*duplicateShareSet
	evictedShareCache    map[string]*evictedCacheEntry
	lastJob              *Job
	lastClean            bool
	notifySeq            uint64 // Incremented each job notification to ensure unique coinbase
	jobScriptTime        map[string]int64
	banUntil             time.Time
	banReason            string
	lastPenalty          time.Time
	invalidSubs          int
	lastProtoViolation   time.Time
	protoViolations      int
	versionRoll          bool
	versionMask          uint32
	poolMask             uint32
	minerMask            uint32
	minVerBits           int
	lastShareHash        string
	lastShareAccepted    bool
	lastShareDifficulty  float64
	lastShareDetail      *ShareDetail
	lastRejectReason     string
	walletMu             sync.Mutex
	workerWallets        map[string]workerWalletState
	subscribed           bool
	authorized           bool
	cleanupOnce          sync.Once
	// If true, VarDiff adjustments are disabled for this miner and the
	// current difficulty is treated as fixed (typically from suggest_difficulty).
	lockDifficulty bool
	// bootstrapDone tracks whether we've already performed the initial
	// "bootstrap" vardiff move for this connection.
	bootstrapDone bool
	// restoredRecentDiff is set when we restore a worker's persisted
	// difficulty after a short disconnect so we can skip bootstrap and
	// suggested-difficulty overrides on reconnect.
	restoredRecentDiff   bool
	minerType            string
	minerClientName      string
	minerClientVersion   string
	extranonceSubscribed bool
	// connectedAt is the time this miner connection was established,
	// used as the zero point for per-share timing in detail logs.
	connectedAt time.Time
	// lastActivity tracks when we last saw a RPC message from this miner.
	lastActivity time.Time
	// stratumMsgWindowStart/stratumMsgCount track per-connection Stratum message rate.
	stratumMsgWindowStart time.Time
	stratumMsgCount       int
	// lastHashrateUpdate tracks the last time we updated the per-connection
	// hashrate EMA so we can apply a time-based decay between shares.
	lastHashrateUpdate time.Time
	// hashrateSampleCount counts how many shares have been recorded since the
	// last EMA update so we can ensure the window spans enough work.
	hashrateSampleCount int
	// hashrateAccumulatedDiff accumulates credited difficulties between samples.
	hashrateAccumulatedDiff float64
	// jobDifficulty records the difficulty in effect when each job notify
	// was sent to this miner so we can credit shares with the assigned
	// target even if vardiff changes before the share arrives.
	jobDifficulty map[string]float64
	// rollingHashrateValue holds the current EMA-smoothed hashrate estimate
	// for this connection, derived from accepted work over time.
	rollingHashrateValue float64
	// isTLSConnection tracks whether this miner connected over the TLS listener.
	isTLSConnection bool
	connectionSeq   uint64
	// suggestDiffProcessed tracks whether we've already processed mining.suggest_difficulty
	// during the initialization phase. Subsequent suggests will be ignored to prevent
	// repeated keepalive messages from disrupting vardiff adjustments.
	suggestDiffProcessed bool
	initialWorkScheduled bool
	initialWorkSent      bool
}

type rpcCaller interface {
	callCtx(ctx context.Context, method string, params interface{}, out interface{}) error
}

// submitBlockWithFastRetry aggressively retries submitblock without backoff
// to maximize the chance of winning the propagation race. It retries every
// 100ms until either submitblock succeeds, a newer job height is observed,
// or a safety window elapses.
func (mc *MinerConn) submitBlockWithFastRetry(job *Job, workerName, hashHex, blockHex string, submitRes *interface{}) error {
	const (
		retryInterval = 100 * time.Millisecond
		// rpcCallTimeout bounds each individual RPC call so a hung bitcoind
		// doesn't block the retry loop indefinitely.
		rpcCallTimeout = 5 * time.Second
		// confirmTimeout bounds getblockheader checks used to detect cases where
		// submitblock may have succeeded but the RPC response timed out.
		confirmTimeout = 2 * time.Second
		// maxRetryWindow is a final safety cap; in practice we expect to
		// stop much sooner when a new block is seen. Using a full block
		// interval keeps us racing hard for rare finds.
		maxRetryWindow = 10 * time.Minute
	)

	start := time.Now()
	attempt := 0
	var lastErr error

	blockAccepted := func() bool {
		if mc.rpc == nil || hashHex == "" {
			return false
		}
		// If bitcoind is overloaded, it's possible for submitblock to
		// succeed server-side while our client-side context times out.
		// Confirm by checking whether the block hash is now known.
		var header struct {
			Confirmations int64 `json:"confirmations"`
		}
		ctx, cancel := context.WithTimeout(context.Background(), confirmTimeout)
		err := mc.rpc.callCtx(ctx, "getblockheader", []interface{}{hashHex, true}, &header)
		cancel()
		// Only treat as success when the block is in the best chain.
		// (Orphaned blocks can still be "known" but will have confirmations=-1.)
		return err == nil && header.Confirmations >= 1
	}

	for {
		attempt++

		// Use a per-call timeout to prevent indefinite hangs on unresponsive RPC.
		// The retry loop continues regardless; we just don't want one call to block forever.
		callCtx, cancel := context.WithTimeout(context.Background(), rpcCallTimeout)
		err := mc.rpc.callCtx(callCtx, "submitblock", []interface{}{blockHex}, submitRes)
		cancel()

		if err == nil {
			if attempt > 1 {
				logger.Info("submitblock succeeded after retries",
					"attempts", attempt,
					"worker", mc.minerName(workerName),
					"hash", hashHex,
				)
			}
			return nil
		}
		lastErr = err

		// If submitblock timed out client-side, check whether the block was
		// accepted anyway. This commonly happens when bitcoind's RPC work
		// queue is saturated.
		if errors.Is(err, context.DeadlineExceeded) && blockAccepted() {
			logger.Warn("submitblock timed out but block is in chain; treating as success",
				"attempts", attempt,
				"worker", mc.minerName(workerName),
				"hash", hashHex,
			)
			return nil
		}

		// Log the first failure loudly; subsequent failures are summarized
		// when we eventually give up.
		if attempt == 1 {
			logger.Error("submitblock error; retrying aggressively",
				"error", err,
				"worker", mc.minerName(workerName),
				"hash", hashHex,
			)
		}

		// If we've already seen a newer template height, there's no point
		// continuing to spam submitblock for this block.
		if mc.jobMgr != nil && job != nil {
			if cur := mc.jobMgr.CurrentJob(); cur != nil && cur.Template.Height > job.Template.Height {
				logger.Warn("submitblock giving up after new block seen",
					"original_height", job.Template.Height,
					"current_height", cur.Template.Height,
					"attempts", attempt,
					"error", err,
				)
				return err
			}
		}

		// Safety stop: avoid spinning forever if the node is persistently
		// unreachable or rejects the block.
		if time.Since(start) >= maxRetryWindow {
			logger.Error("submitblock giving up after retry window",
				"attempts", attempt,
				"duration", time.Since(start),
				"error", lastErr,
			)
			return lastErr
		}

		time.Sleep(retryInterval)
	}
}

// statsWorker processes stats updates asynchronously from a buffered channel.
// This eliminates lock contention on the hot path (share submission).
func (mc *MinerConn) statsWorker() {
	defer mc.statsWg.Done()

	for update := range mc.statsUpdates {
		mc.statsMu.Lock()
		mc.ensureWindowLocked(update.timestamp)

		if update.worker != "" {
			if mc.stats.Worker != update.worker {
				mc.stats.Worker = update.worker
				mc.stats.WorkerSHA256 = workerNameHash(update.worker)
			} else if mc.stats.WorkerSHA256 == "" {
				mc.stats.WorkerSHA256 = workerNameHash(update.worker)
			}
		}

		mc.stats.WindowSubmissions++
		if update.accepted {
			mc.stats.Accepted++
			mc.stats.WindowAccepted++
			if update.creditedDiff >= 0 {
				mc.stats.TotalDifficulty += update.creditedDiff
				mc.stats.WindowDifficulty += update.creditedDiff
				mc.updateHashrateLocked(update.creditedDiff, update.timestamp)
			}
		} else {
			mc.stats.Rejected++
		}
		mc.stats.LastShare = update.timestamp

		mc.lastShareHash = update.shareHash
		mc.lastShareAccepted = update.accepted
		mc.lastShareDifficulty = update.shareDiff
		mc.lastShareDetail = update.detail
		if !update.accepted && update.reason != "" {
			mc.lastRejectReason = update.reason
		}
		mc.statsMu.Unlock()
	}
}

func (mc *MinerConn) cleanup() {
	mc.cleanupOnce.Do(func() {
		if mc.metrics != nil {
			if connSeq := atomic.LoadUint64(&mc.connectionSeq); connSeq != 0 {
				mc.metrics.RemoveConnectionHashrate(connSeq)
			}
		}
		mc.unregisterRegisteredWorker()

		// Close stats channel and wait for worker to finish processing
		close(mc.statsUpdates)
		mc.statsWg.Wait()

		mc.statsMu.Lock()
		mc.stats.WindowStart = time.Time{}
		mc.stats.WindowAccepted = 0
		mc.stats.WindowSubmissions = 0
		mc.stats.WindowDifficulty = 0
		mc.lastHashrateUpdate = time.Time{}
		mc.rollingHashrateValue = 0
		mc.statsMu.Unlock()
		if mc.jobMgr != nil && mc.jobCh != nil {
			mc.jobMgr.Unsubscribe(mc.jobCh)
		}
		if mc.conn != nil {
			_ = mc.conn.Close()
		}
	})
}

func (mc *MinerConn) Close(reason string) {
	if reason == "" {
		reason = "shutdown"
	}
	logger.Info("closing miner", "remote", mc.id, "reason", reason)
	mc.cleanup()
}

// workerWalletDataRef returns a validated worker wallet entry without copying
// the stored script. The returned script must be treated as read-only.
//
// This exists to avoid per-share allocations in hot paths (coinbase/header
// rebuild). For external/state snapshot callers, prefer workerWalletData.
func (mc *MinerConn) workerWalletDataRef(worker string) (string, []byte, bool) {
	if worker == "" {
		return "", nil, false
	}
	mc.walletMu.Lock()
	defer mc.walletMu.Unlock()
	info, ok := mc.workerWallets[worker]
	if !ok || !info.validated {
		return "", nil, false
	}
	return info.address, info.script, true
}

// workerPayoutScript returns the cached payout script for a worker, if any.
// This is populated during wallet validation and will be used in a future
// dual-payout coinbase layout.
func (mc *MinerConn) workerPayoutScript(worker string) []byte {
	if worker == "" {
		return nil
	}
	_, script, ok := mc.workerWalletDataRef(worker)
	if !ok {
		return nil
	}
	return script
}

func workerBaseAddress(worker string) string {
	raw := strings.TrimSpace(worker)
	if raw == "" {
		return ""
	}
	if parts := strings.SplitN(raw, ".", 2); len(parts) > 1 {
		raw = parts[0]
	}
	return sanitizePayoutAddress(raw)
}

func cloneBytes(b []byte) []byte {
	if len(b) == 0 {
		return nil
	}
	c := make([]byte, len(b))
	copy(c, b)
	return c
}

func (mc *MinerConn) workerWalletData(worker string) (string, []byte, bool) {
	if worker == "" {
		return "", nil, false
	}
	mc.walletMu.Lock()
	defer mc.walletMu.Unlock()
	info, ok := mc.workerWallets[worker]
	if !ok || !info.validated {
		return "", nil, false
	}
	return info.address, cloneBytes(info.script), true
}

func (mc *MinerConn) setWorkerWallet(worker, addr string, script []byte) {
	if worker == "" || addr == "" || len(script) == 0 {
		return
	}
	mc.walletMu.Lock()
	if mc.workerWallets == nil {
		mc.workerWallets = make(map[string]workerWalletState, 4) // Pre-allocate for typical worker count
	}
	mc.workerWallets[worker] = workerWalletState{
		address:   addr,
		script:    cloneBytes(script),
		validated: true,
	}
	mc.walletMu.Unlock()
}

func (mc *MinerConn) assignConnectionSeq() {
	if atomic.LoadUint64(&mc.connectionSeq) != 0 {
		return
	}
	id := atomic.AddUint64(&nextConnectionID, 1)
	atomic.StoreUint64(&mc.connectionSeq, id)
}

func (mc *MinerConn) connectionIDString() string {
	seq := atomic.LoadUint64(&mc.connectionSeq)
	if seq == 0 {
		return ""
	}
	return encodeBase58Uint64(seq - 1)
}

const base58Alphabet = "123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz"

func encodeBase58Uint64(value uint64) string {
	if value == 0 {
		return string(base58Alphabet[0])
	}
	var buf [16]byte
	i := len(buf)
	for value > 0 {
		i--
		buf[i] = base58Alphabet[value%58]
		value /= 58
	}
	return string(buf[i:])
}

func (mc *MinerConn) ensureWorkerWallet(worker string) (string, []byte, bool) {
	if worker == "" {
		return "", nil, false
	}
	if addr, script, ok := mc.workerWalletData(worker); ok {
		return addr, script, true
	}
	base := workerBaseAddress(worker)
	if base == "" {
		return "", nil, false
	}
	script, err := scriptForAddress(base, ChainParams())
	if err != nil {
		return "", nil, false
	}
	mc.setWorkerWallet(worker, base, script)
	return base, cloneBytes(script), true
}

func (mc *MinerConn) registerWorker(worker string) *MinerConn {
	if worker == "" || mc.workerRegistry == nil {
		return nil
	}
	hash := ""
	mc.statsMu.Lock()
	if mc.stats.Worker == worker {
		hash = strings.TrimSpace(mc.stats.WorkerSHA256)
	}
	mc.statsMu.Unlock()
	if hash == "" {
		hash = workerNameHash(worker)
	}
	if hash == "" {
		return nil
	}
	if mc.registeredWorkerHash == hash {
		return nil
	}
	if mc.registeredWorkerHash != "" {
		prevWallet := workerBaseAddress(mc.registeredWorker)
		prevWalletHash := workerNameHash(prevWallet)
		mc.workerRegistry.unregister(mc.registeredWorkerHash, prevWalletHash, mc)
	}
	wallet := workerBaseAddress(worker)
	walletHash := workerNameHash(wallet)
	prev := mc.workerRegistry.register(hash, walletHash, mc)
	mc.registeredWorker = worker
	mc.registeredWorkerHash = hash
	mc.syncSavedWorkerState(hash)
	return prev
}

func (mc *MinerConn) unregisterRegisteredWorker() {
	if mc.workerRegistry == nil || mc.registeredWorkerHash == "" {
		return
	}
	wallet := workerBaseAddress(mc.registeredWorker)
	walletHash := workerNameHash(wallet)
	mc.workerRegistry.unregister(mc.registeredWorkerHash, walletHash, mc)
	mc.registeredWorker = ""
	mc.registeredWorkerHash = ""
	mc.savedWorkerTracked = false
	mc.savedWorkerBestDiff = 0
}

func (mc *MinerConn) syncSavedWorkerState(hash string) {
	if mc == nil {
		return
	}
	mc.savedWorkerTracked = false
	mc.savedWorkerBestDiff = 0
	if mc.savedWorkerStore == nil {
		return
	}
	hash = strings.TrimSpace(hash)
	if hash == "" {
		return
	}
	best, ok, err := mc.savedWorkerStore.BestDifficultyForHash(hash)
	if err != nil {
		logger.Warn("saved worker best difficulty lookup failed", "error", err, "hash", hash)
		return
	}
	mc.savedWorkerBestDiff = best
	mc.savedWorkerTracked = ok
}

func (mc *MinerConn) maybeUpdateSavedWorkerBestDiff(diff float64) {
	if mc == nil || !mc.savedWorkerTracked || mc.savedWorkerStore == nil {
		return
	}
	if diff <= mc.savedWorkerBestDiff {
		return
	}
	hash := mc.registeredWorkerHash
	if hash == "" {
		return
	}
	if _, err := mc.savedWorkerStore.UpdateSavedWorkerBestDifficulty(hash, diff); err != nil {
		logger.Warn("saved worker best difficulty update failed", "error", err, "hash", hash)
	}
	mc.savedWorkerBestDiff = diff
}

// dualPayoutParams returns the pool and worker payout scripts and fee
// parameters for a job, if all required pieces are available. It does not
// mutate the Job; callers use the returned values with
// buildDualPayoutCoinbaseParts when constructing coinbase data in the
// dual-payout path.
// Returns false (single-payout) when:
// - Pool fee is 0% (entire reward goes to worker)
// - Worker wallet matches pool wallet (same beneficiary)
// - Worker has no valid payout script
func (mc *MinerConn) dualPayoutParams(job *Job, worker string) (poolScript []byte, workerScript []byte, totalValue int64, feePercent float64, ok bool) {
	if job == nil || job.CoinbaseValue <= 0 {
		return nil, nil, 0, 0, false
	}
	if len(job.PayoutScript) == 0 {
		return nil, nil, 0, 0, false
	}
	// If the pool fee is 0%, there's no need for dual-payout since the entire
	// block reward goes to the worker. Use single-output coinbase.
	if mc.cfg.PoolFeePercent <= 0 {
		return nil, nil, 0, 0, false
	}
	addr, script, ok := mc.workerWalletDataRef(worker)
	if !ok || len(script) == 0 {
		return nil, nil, 0, 0, false
	}
	// If the worker's wallet address is the same as the pool payout address,
	// there is no benefit to building a dual-payout coinbase; treat it as a
	// single-output payout to that address.
	if addr != "" && strings.EqualFold(addr, mc.cfg.PayoutAddress) {
		return nil, nil, 0, 0, false
	}

	return job.PayoutScript, script, job.CoinbaseValue, mc.cfg.PoolFeePercent, true
}

func NewMinerConn(ctx context.Context, c net.Conn, jobMgr *JobManager, rpc rpcCaller, cfg Config, metrics *PoolMetrics, accounting *AccountStore, workerRegistry *workerConnectionRegistry, workerLists *workerListStore, notifier *discordNotifier, isTLS bool) *MinerConn {
	if ctx == nil {
		ctx = context.Background()
	}
	now := time.Now()
	if cfg.ConnectionTimeout <= 0 {
		cfg.ConnectionTimeout = defaultConnectionTimeout
	}
	jobCh := jobMgr.Subscribe()
	en1 := jobMgr.NextExtranonce1()
	maxRecentJobs := cfg.MaxRecentJobs
	if maxRecentJobs <= 0 {
		maxRecentJobs = defaultRecentJobs
	}

	mask := cfg.VersionMask
	if mask == 0 && !cfg.VersionMaskConfigured {
		mask = defaultVersionMask
	}
	minBits := cfg.MinVersionBits
	if mask == 0 {
		minBits = 0
	} else {
		if minBits <= 0 {
			minBits = 1
		}
		if minBits > bits.OnesCount32(mask) {
			minBits = bits.OnesCount32(mask)
		}
	}

	vdiff := defaultVarDiff
	// Difficulty clamps:
	// - cfg.MinDifficulty == 0 disables the minimum clamp (no lower bound).
	// - cfg.MaxDifficulty == 0 disables the maximum clamp (no upper bound).
	// - values > 0 enable a clamp at that value.
	if cfg.MinDifficulty == 0 {
		vdiff.MinDiff = 0
	} else if cfg.MinDifficulty > 0 {
		vdiff.MinDiff = cfg.MinDifficulty
	}
	if cfg.MaxDifficulty == 0 {
		vdiff.MaxDiff = 0
	} else if cfg.MaxDifficulty > 0 {
		// If the defaults ever include a max clamp, use the tighter one.
		if vdiff.MaxDiff <= 0 || cfg.MaxDifficulty < vdiff.MaxDiff {
			vdiff.MaxDiff = cfg.MaxDifficulty
		}
	}
	if vdiff.MaxDiff > 0 && vdiff.MinDiff > vdiff.MaxDiff {
		vdiff.MinDiff = vdiff.MaxDiff
	}

	// Start connections at the configured default difficulty when set; otherwise
	// use the minimum clamp or a conservative fallback and let VarDiff adjust.
	initialDiff := defaultMinDifficulty
	if cfg.DefaultDifficulty > 0 {
		initialDiff = cfg.DefaultDifficulty
	} else if cfg.MinDifficulty > 0 {
		initialDiff = cfg.MinDifficulty
	}
	if initialDiff <= 0 {
		initialDiff = 1.0
	}

	var shareCache map[string]*duplicateShareSet
	var evictedShareCache map[string]*evictedCacheEntry
	if cfg.CheckDuplicateShares {
		shareCache = make(map[string]*duplicateShareSet, maxRecentJobs)
		evictedShareCache = make(map[string]*evictedCacheEntry)
	}

	mc := &MinerConn{
		ctx:               ctx,
		id:                c.RemoteAddr().String(),
		conn:              c,
		writer:            bufio.NewWriter(c),
		reader:            bufio.NewReaderSize(c, maxStratumMessageSize),
		jobMgr:            jobMgr,
		rpc:               rpc,
		cfg:               cfg,
		extranonce1:       en1,
		jobCh:             jobCh,
		vardiff:           vdiff,
		metrics:           metrics,
		accounting:        accounting,
		workerRegistry:    workerRegistry,
		savedWorkerStore:  workerLists,
		discordNotifier:   notifier,
		activeJobs:        make(map[string]*Job, maxRecentJobs), // Pre-allocate for expected job count
		connectedAt:       now,
		lastActivity:      now,
		jobDifficulty:     make(map[string]float64, maxRecentJobs), // Pre-allocate for expected job count
		shareCache:        shareCache,
		evictedShareCache: evictedShareCache,
		maxRecentJobs:     maxRecentJobs,
		lastPenalty:       time.Now(),
		versionRoll:       false,
		versionMask:       0,
		poolMask:          mask,
		minerMask:         0,
		minVerBits:        minBits,
		bootstrapDone:     false,
		isTLSConnection:   isTLS,
		statsUpdates:      make(chan statsUpdate, 1000), // Buffered for up to 1000 pending stats updates
	}

	// Initialize atomic fields
	atomicStoreFloat64(&mc.difficulty, initialDiff)
	mc.shareTarget.Store(targetFromDifficulty(initialDiff))

	// Start stats worker goroutine
	mc.statsWg.Add(1)
	go mc.statsWorker()

	return mc
}

func (mc *MinerConn) handle() {
	defer mc.cleanup()
	if debugLogging || verboseLogging {
		logger.Info("miner connected", "remote", mc.id, "extranonce1", hex.EncodeToString(mc.extranonce1))
	}

	for {
		now := time.Now()
		if mc.ctx.Err() != nil {
			return
		}
		if expired, reason := mc.idleExpired(now); expired {
			logger.Warn("closing miner for idle timeout", "remote", mc.id, "reason", reason)
			return
		}
		deadline := now.Add(mc.currentReadTimeout())
		if err := mc.conn.SetReadDeadline(deadline); err != nil {
			if mc.ctx.Err() != nil {
				return
			}
			logger.Error("set read deadline failed", "remote", mc.id, "error", err)
			return
		}

		line, err := mc.reader.ReadBytes('\n')
		now = time.Now()
		if err != nil {
			if errors.Is(err, bufio.ErrBufferFull) {
				logger.Warn("closing miner for oversized message", "remote", mc.id, "limit_bytes", maxStratumMessageSize)
				if banned, count := mc.noteProtocolViolation(now); banned {
					mc.logBan("oversized stratum message", mc.currentWorker(), count)
				}
				return
			}
			if nErr, ok := err.(net.Error); ok && nErr.Timeout() {
				if expired, reason := mc.idleExpired(now); expired {
					logger.Warn("closing miner for idle timeout", "remote", mc.id, "reason", reason)
					return
				}
				continue
			}
			if err != io.EOF && !errors.Is(err, net.ErrClosed) {
				logger.Error("read error", "remote", mc.id, "error", err)
			}
			return
		}
		if len(line) > maxStratumMessageSize {
			logger.Warn("closing miner for oversized message", "remote", mc.id, "limit_bytes", maxStratumMessageSize)
			if banned, count := mc.noteProtocolViolation(now); banned {
				mc.logBan("oversized stratum message", mc.currentWorker(), count)
			}
			return
		}

		logNetMessage("recv", line)
		line = bytes.TrimSpace(line)
		if len(line) == 0 {
			continue
		}
		mc.recordActivity(now)
		if mc.stratumMsgRateLimitExceeded(now) {
			logger.Warn("closing miner for stratum message rate limit",
				"remote", mc.id,
				"limit_per_min", mc.cfg.StratumMessagesPerMinute,
			)
			mc.banFor("stratum message rate limit", time.Hour, mc.currentWorker())
			return
		}

		if method, id, ok := sniffStratumMethodID(line); ok {
			switch method {
			case "mining.ping":
				mc.writePongResponse(id)
				continue
			case "mining.get_transactions":
				mc.writeEmptySliceResponse(id)
				continue
			case "mining.capabilities":
				mc.writeTrueResponse(id)
				continue
			case "mining.extranonce.subscribe":
				mc.handleExtranonceSubscribe(&StratumRequest{ID: id})
				continue
			case "mining.subscribe":
				if params, ok := sniffStratumStringParams(line, 1); ok {
					req := buildStringRequest(id, method, params)
					mc.handleSubscribe(&req)
					continue
				}
			case "mining.authorize":
				if params, ok := sniffStratumStringParams(line, 2); ok {
					req := buildStringRequest(id, method, params)
					mc.handleAuthorize(&req)
					continue
				}
			case "mining.submit":
				// Fast-path: most mining.submit payloads are small and string-only.
				// Avoid full JSON unmarshal on the connection goroutine to reduce
				// allocations and tail latency under load.
				if params, ok := sniffStratumStringParams(line, 6); ok && (len(params) == 5 || len(params) == 6) {
					mc.handleSubmitStringParams(id, params)
					continue
				}
			}
		}
		var req StratumRequest
		if err := fastJSONUnmarshal(line, &req); err != nil {
			logger.Warn("json error from miner", "remote", mc.id, "error", err)
			if banned, count := mc.noteProtocolViolation(now); banned {
				mc.logBan("invalid stratum json", mc.currentWorker(), count)
			}
			return
		}

		switch req.Method {
		case "mining.subscribe":
			mc.handleSubscribe(&req)
		case "mining.authorize":
			mc.handleAuthorize(&req)
		case "mining.submit":
			mc.handleSubmit(&req)
		case "mining.configure":
			mc.handleConfigure(&req)
		case "mining.extranonce.subscribe":
			mc.handleExtranonceSubscribe(&req)
		case "mining.suggest_difficulty":
			mc.suggestDifficulty(&req)
		case "mining.suggest_target":
			mc.suggestTarget(&req)
		case "mining.ping":
			// Respond to keepalive ping with pong
			mc.writePongResponse(req.ID)
		case "mining.get_transactions":
			// Client requests transaction hashes for current job. We don't
			// support this but acknowledge to avoid breaking miners that send it.
			mc.writeEmptySliceResponse(req.ID)
		case "mining.capabilities":
			// Draft extension where client advertises its capabilities.
			// Acknowledge receipt but we don't need to act on it.
			mc.writeTrueResponse(req.ID)
		default:
			// Silently ignore unknown methods to avoid confusing miners that
			// send non-standard extensions. Log at debug level for diagnostics.
			if debugLogging {
				logger.Debug("ignoring unknown stratum method", "remote", mc.id, "method", req.Method)
			}
		}

	}
}

func (mc *MinerConn) scheduleInitialWork() {
	mc.initWorkMu.Lock()
	if mc.initialWorkScheduled || mc.initialWorkSent {
		mc.initWorkMu.Unlock()
		return
	}
	mc.initialWorkScheduled = true
	mc.initWorkMu.Unlock()

	go func() {
		time.Sleep(defaultInitialDifficultyDelay)
		mc.sendInitialWork()
	}()
}

func (mc *MinerConn) maybeSendInitialWork() {
	mc.initWorkMu.Lock()
	alreadySent := mc.initialWorkSent
	mc.initWorkMu.Unlock()
	if alreadySent {
		return
	}
	mc.sendInitialWork()
}

func (mc *MinerConn) sendInitialWork() {
	mc.initWorkMu.Lock()
	if mc.initialWorkSent {
		mc.initWorkMu.Unlock()
		return
	}
	mc.initialWorkSent = true
	mc.initWorkMu.Unlock()

	if !mc.authorized || !mc.listenerOn {
		return
	}

	// Respect suggested difficulty if already processed. Otherwise, fall back
	// to a sane default/minimum so miners have a starting target.
	if !mc.suggestDiffProcessed && !mc.restoredRecentDiff {
		diff := mc.cfg.DefaultDifficulty
		if diff <= 0 {
			diff = mc.vardiff.MinDiff
		}
		if diff > 0 {
			mc.setDifficulty(diff)
		}
	}

	// First job always has clean_jobs=true so the miner starts fresh.
	if job := mc.jobMgr.CurrentJob(); job != nil {
		mc.sendNotifyFor(job, true)
	}
}

func (mc *MinerConn) writeJSON(v interface{}) error {
	b, err := fastJSONMarshal(v)
	if err != nil {
		return err
	}
	b = append(b, '\n')
	return mc.writeBytes(b)
}

func (mc *MinerConn) writeBytes(b []byte) error {
	mc.writeMu.Lock()
	defer mc.writeMu.Unlock()

	if err := mc.conn.SetWriteDeadline(time.Now().Add(stratumWriteTimeout)); err != nil {
		return err
	}
	logNetMessage("send", b)
	if _, err := mc.writer.Write(b); err != nil {
		return err
	}
	return mc.writer.Flush()
}

// currentReadTimeout returns a dynamic read timeout based on whether the
// miner has proven itself by submitting accepted shares. New/idle
// connections get a short timeout to protect against floods; once a miner
// has submitted a few valid shares we switch to the configured, longer
// timeout.
func (mc *MinerConn) currentReadTimeout() time.Duration {
	base := mc.cfg.ConnectionTimeout
	if base <= 0 {
		base = defaultConnectionTimeout
	}

	mc.statsMu.Lock()
	accepted := mc.stats.Accepted
	mc.statsMu.Unlock()

	if accepted < 3 {
		return initialReadTimeout
	}
	return base
}

func (mc *MinerConn) writeResponse(resp StratumResponse) {
	if err := mc.writeJSON(resp); err != nil {
		logger.Error("write error", "remote", mc.id, "error", err)
	}
}

var (
	cannedPongSuffix       = []byte(`,"result":"pong","error":null}`)
	cannedEmptySliceSuffix = []byte(`,"result":[],"error":null}`)
	cannedTrueSuffix       = []byte(`,"result":true,"error":null}`)
)

func (mc *MinerConn) writePongResponse(id interface{}) {
	mc.sendCannedResponse("pong", id, cannedPongSuffix)
}

func (mc *MinerConn) writeEmptySliceResponse(id interface{}) {
	mc.sendCannedResponse("empty slice", id, cannedEmptySliceSuffix)
}

func (mc *MinerConn) writeTrueResponse(id interface{}) {
	mc.sendCannedResponse("true", id, cannedTrueSuffix)
}

func (mc *MinerConn) sendCannedResponse(label string, id interface{}, suffix []byte) {
	if err := mc.writeCannedResponse(id, suffix); err != nil {
		logger.Error("write canned response", "remote", mc.id, "label", label, "error", err)
	}
}

func (mc *MinerConn) writeCannedResponse(id interface{}, suffix []byte) error {
	buf := make([]byte, 0, 64)
	buf = append(buf, `{"id":`...)
	var err error
	buf, err = appendJSONValue(buf, id)
	if err != nil {
		return err
	}
	buf = append(buf, suffix...)
	buf = append(buf, '\n')
	return mc.writeBytes(buf)
}

func appendJSONValue(buf []byte, value interface{}) ([]byte, error) {
	switch v := value.(type) {
	case nil:
		return append(buf, "null"...), nil
	case string:
		return strconv.AppendQuote(buf, v), nil
	case bool:
		if v {
			return append(buf, "true"...), nil
		}
		return append(buf, "false"...), nil
	case json.Number:
		return append(buf, v...), nil
	case float64:
		return strconv.AppendFloat(buf, v, 'g', -1, 64), nil
	case float32:
		return strconv.AppendFloat(buf, float64(v), 'g', -1, 32), nil
	case int:
		return strconv.AppendInt(buf, int64(v), 10), nil
	case int8:
		return strconv.AppendInt(buf, int64(v), 10), nil
	case int16:
		return strconv.AppendInt(buf, int64(v), 10), nil
	case int32:
		return strconv.AppendInt(buf, int64(v), 10), nil
	case int64:
		return strconv.AppendInt(buf, v, 10), nil
	case uint:
		return strconv.AppendUint(buf, uint64(v), 10), nil
	case uint8:
		return strconv.AppendUint(buf, uint64(v), 10), nil
	case uint16:
		return strconv.AppendUint(buf, uint64(v), 10), nil
	case uint32:
		return strconv.AppendUint(buf, uint64(v), 10), nil
	case uint64:
		return strconv.AppendUint(buf, v, 10), nil
	default:
		b, err := fastJSONMarshal(value)
		if err != nil {
			return buf, err
		}
		return append(buf, b...), nil
	}
}

func buildStringRequest(id interface{}, method string, params []string) StratumRequest {
	iface := make([]interface{}, len(params))
	for i, p := range params {
		iface[i] = p
	}
	return StratumRequest{
		ID:     id,
		Method: method,
		Params: iface,
	}
}

func (mc *MinerConn) listenJobs() {
	defer func() {
		if r := recover(); r != nil {
			logger.Error("listenJobs panic recovered", "remote", mc.id, "panic", r)
			// Restart the listener after a brief delay to avoid tight panic loops
			time.Sleep(100 * time.Millisecond)
			go mc.listenJobs()
		}
	}()

	for job := range mc.jobCh {
		mc.sendNotifyFor(job, false)
	}
}

func (mc *MinerConn) minerName(fallback string) string {
	mc.statsMu.Lock()
	worker := mc.stats.Worker
	mc.statsMu.Unlock()
	if worker != "" {
		return worker
	}
	if fallback != "" {
		return fallback
	}
	return mc.id
}

func (mc *MinerConn) minerClientInfo() (minerType, name, version string) {
	mc.stateMu.Lock()
	minerType = mc.minerType
	name = mc.minerClientName
	version = mc.minerClientVersion
	mc.stateMu.Unlock()
	return minerType, name, version
}

func (mc *MinerConn) currentWorker() string {
	mc.statsMu.Lock()
	defer mc.statsMu.Unlock()
	return mc.stats.Worker
}

func (mc *MinerConn) updateWorker(worker string) string {
	if worker == "" {
		return mc.minerName("")
	}
	mc.statsMu.Lock()
	if mc.stats.Worker != worker {
		mc.stats.Worker = worker
		mc.stats.WorkerSHA256 = workerNameHash(worker)
	} else if mc.stats.WorkerSHA256 == "" {
		mc.stats.WorkerSHA256 = workerNameHash(worker)
	}
	mc.statsMu.Unlock()
	return worker
}

func (mc *MinerConn) ensureWindowLocked(now time.Time) {
	if mc.stats.WindowStart.IsZero() {
		mc.stats.WindowStart = now
		mc.stats.WindowDifficulty = 0
		return
	}
	if now.Sub(mc.stats.WindowStart) > mc.vardiff.AdjustmentWindow*2 {
		mc.stats.WindowStart = now
		mc.stats.WindowAccepted = 0
		mc.stats.WindowSubmissions = 0
		mc.stats.WindowDifficulty = 0
	}
}

// recordShare updates accounting for a submitted share. creditedDiff is the
// target difficulty we assigned for this share (used for hashrate), while
// shareDiff is the difficulty implied by the submitted hash (used for
// display/detail). They may differ when vardiff changed between notify and
// submit; we always want hashrate to use the assigned target.
func (mc *MinerConn) recordShare(worker string, accepted bool, creditedDiff float64, shareDiff float64, reason string, shareHash string, detail *ShareDetail, now time.Time) {
	// Send update to async stats worker instead of blocking on mutex
	update := statsUpdate{
		worker:       worker,
		accepted:     accepted,
		creditedDiff: creditedDiff,
		shareDiff:    shareDiff,
		reason:       reason,
		shareHash:    shareHash,
		detail:       detail,
		timestamp:    now,
	}

	select {
	case mc.statsUpdates <- update:
		// Successfully queued for async processing
	default:
		// Channel full, process synchronously as fallback
		mc.recordShareSync(update)
	}

	if mc.metrics != nil {
		mc.metrics.RecordShare(accepted, reason)
	}
}

// recordShareSync is the fallback synchronous stats update (only when channel is full)
func (mc *MinerConn) recordShareSync(update statsUpdate) {
	mc.statsMu.Lock()
	mc.ensureWindowLocked(update.timestamp)
	if update.worker != "" {
		if mc.stats.Worker != update.worker {
			mc.stats.Worker = update.worker
			mc.stats.WorkerSHA256 = workerNameHash(update.worker)
		} else if mc.stats.WorkerSHA256 == "" {
			mc.stats.WorkerSHA256 = workerNameHash(update.worker)
		}
	}
	mc.stats.WindowSubmissions++
	if update.accepted {
		mc.stats.Accepted++
		mc.stats.WindowAccepted++
		if update.creditedDiff >= 0 {
			mc.stats.TotalDifficulty += update.creditedDiff
			mc.stats.WindowDifficulty += update.creditedDiff
			mc.updateHashrateLocked(update.creditedDiff, update.timestamp)
		}
	} else {
		mc.stats.Rejected++
	}
	mc.stats.LastShare = update.timestamp

	mc.lastShareHash = update.shareHash
	mc.lastShareAccepted = update.accepted
	mc.lastShareDifficulty = update.shareDiff
	mc.lastShareDetail = update.detail
	if !update.accepted && update.reason != "" {
		mc.lastRejectReason = update.reason
	}
	mc.statsMu.Unlock()
}

func (mc *MinerConn) trackBestShare(worker, hash string, difficulty float64, now time.Time) {
	if mc.metrics == nil {
		return
	}
	mc.metrics.TrackBestShare(worker, hash, difficulty, now)
}

func (mc *MinerConn) snapshotStats() MinerStats {
	mc.statsMu.Lock()
	defer mc.statsMu.Unlock()
	return mc.stats
}

func (mc *MinerConn) snapshotStatsWithRates(now time.Time) (stats MinerStats, acceptRatePerMin float64, submitRatePerMin float64) {
	mc.statsMu.Lock()
	defer mc.statsMu.Unlock()
	stats = mc.stats
	if stats.WindowStart.IsZero() {
		return stats, 0, 0
	}
	window := now.Sub(stats.WindowStart)
	if window <= 0 {
		return stats, 0, 0
	}
	acceptRatePerMin = float64(stats.WindowAccepted) / window.Minutes()
	submitRatePerMin = float64(stats.WindowSubmissions) / window.Minutes()
	return stats, acceptRatePerMin, submitRatePerMin
}

type minerShareSnapshot struct {
	Stats               MinerStats
	RollingHashrate     float64
	LastShareHash       string
	LastShareAccepted   bool
	LastShareDifficulty float64
	LastShareDetail     *ShareDetail
	LastReject          string
}

func (mc *MinerConn) snapshotShareInfo() minerShareSnapshot {
	mc.statsMu.Lock()
	defer mc.statsMu.Unlock()
	return minerShareSnapshot{
		Stats:               mc.stats,
		RollingHashrate:     mc.rollingHashrateValue,
		LastShareHash:       mc.lastShareHash,
		LastShareAccepted:   mc.lastShareAccepted,
		LastShareDifficulty: mc.lastShareDifficulty,
		LastShareDetail:     mc.lastShareDetail,
		LastReject:          mc.lastRejectReason,
	}
}

func (mc *MinerConn) isBanned(now time.Time) bool {
	mc.stateMu.Lock()
	defer mc.stateMu.Unlock()
	return now.Before(mc.banUntil)
}

func (mc *MinerConn) banDetails() (time.Time, string, int) {
	mc.stateMu.Lock()
	defer mc.stateMu.Unlock()
	return mc.banUntil, mc.banReason, mc.invalidSubs
}

func (mc *MinerConn) logBan(reason, worker string, invalidSubs int) {
	until, banReason, _ := mc.banDetails()
	if banReason == "" {
		banReason = reason
	}
	if mc.accounting != nil && worker != "" {
		mc.accounting.MarkBan(worker, until, banReason)
	}
	logger.Warn("miner banned",
		"miner", mc.minerName(worker),
		"remote", mc.id,
		"reason", banReason,
		"ban_until", until,
		"invalid_submissions", invalidSubs,
	)
}

func (mc *MinerConn) adminBan(reason string, duration time.Duration) {
	if mc == nil {
		return
	}
	if duration <= 0 {
		duration = defaultBanInvalidSubmissionsDuration
	}
	if reason == "" {
		reason = "admin ban"
	}
	mc.stateMu.Lock()
	mc.banUntil = time.Now().Add(duration)
	mc.banReason = reason
	mc.stateMu.Unlock()
	mc.logBan(reason, mc.currentWorker(), 0)
}

func (mc *MinerConn) banFor(reason string, duration time.Duration, worker string) {
	if mc == nil {
		return
	}
	if duration <= 0 {
		duration = defaultBanInvalidSubmissionsDuration
	}
	if reason == "" {
		reason = "ban"
	}
	mc.stateMu.Lock()
	mc.banUntil = time.Now().Add(duration)
	mc.banReason = reason
	mc.stateMu.Unlock()
	mc.logBan(reason, worker, 0)
}
